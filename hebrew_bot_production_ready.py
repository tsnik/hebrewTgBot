# -*- coding: utf-8 -*-

"""
Telegram-–±–æ—Ç "–ü–æ–º–æ—â–Ω–∏–∫ –ø–æ –∏–≤—Ä–∏—Ç—É"
–í–µ—Ä—Å–∏—è: 12.5 (–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –¥–µ—Ç–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ)
–î–∞—Ç–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: 23 –∏—é–ª—è 2025 –≥.

–ö–ª—é—á–µ–≤—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ —ç—Ç–æ–π –≤–µ—Ä—Å–∏–∏:
- DEBUG: –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –ø–æ–¥—Ä–æ–±–Ω–æ–µ –ø–æ—à–∞–≥–æ–≤–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ –º–æ–¥—É–ª–µ –ø–∞—Ä—Å–µ—Ä–∞
  –¥–ª—è –æ–±–ª–µ–≥—á–µ–Ω–∏—è –æ—Ç–ª–∞–¥–∫–∏, –∫–∞–∫ –±—ã–ª–æ –≤ –ø–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω–æ–π –≤–µ—Ä—Å–∏–∏.
- CRITICAL FIX: –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∞ –æ—Å–Ω–æ–≤–Ω–∞—è –ø—Ä–æ–±–ª–µ–º–∞, –∏–∑-–∑–∞ –∫–æ—Ç–æ—Ä–æ–π –±–æ—Ç –Ω–µ –æ—Ç–≤–µ—á–∞–ª
  –∫–∞—Ä—Ç–æ—á–∫–æ–π —Å–ª–æ–≤–∞ –ø–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞. –≠—Ç–æ –±—ã–ª–æ –≤—ã–∑–≤–∞–Ω–æ –ø–æ—Ç–µ—Ä–µ–π
  –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–æ—Å–ª–µ –¥–ª–∏—Ç–µ–ª—å–Ω–æ–π –æ–ø–µ—Ä–∞—Ü–∏–∏ –≤ –ø–æ—Ç–æ–∫–µ. –¢–µ–ø–µ—Ä—å –¥–ª—è –≤—Å–µ—Ö
  –¥–µ–π—Å—Ç–≤–∏–π –ø–æ—Å–ª–µ `await` –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è `context.bot` —Å —è–≤–Ω—ã–º —É–∫–∞–∑–∞–Ω–∏–µ–º
  `chat_id` –∏ `message_id`, —á—Ç–æ —è–≤–ª—è–µ—Ç—Å—è –Ω–∞–¥–µ–∂–Ω—ã–º –ø–æ–¥—Ö–æ–¥–æ–º.
- REFACTOR: –§—É–Ω–∫—Ü–∏—è `display_word_card` –∏ –µ–µ –≤—ã–∑–æ–≤—ã –±—ã–ª–∏ –ø–µ—Ä–µ—Ä–∞–±–æ—Ç–∞–Ω—ã
  –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è `context.bot`, —á—Ç–æ –ø–æ–≤—ã—Å–∏–ª–æ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –∫–æ–¥–∞.
- FIX: –î–æ–±–∞–≤–ª–µ–Ω UNIQUE constraint –≤ —Ç–∞–±–ª–∏—Ü—É user_dictionary –¥–ª—è –∞—Ç–æ–º–∞—Ä–Ω–æ–≥–æ
  –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è "–¥–≤–æ–π–Ω–æ–≥–æ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è" —Å–ª–æ–≤ (race condition).
- PERF: –í–∫–ª—é—á–µ–Ω —Ä–µ–∂–∏–º WAL –¥–ª—è SQLite –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞
  –ø—Ä–∏ –æ–ø–µ—Ä–∞—Ü–∏—è—Ö —á—Ç–µ–Ω–∏—è –∏ –∑–∞–ø–∏—Å–∏ –≤ –ë–î.
"""

import logging
import sqlite3
from datetime import datetime, timedelta
import requests
from bs4 import BeautifulSoup, Tag
import re
import os
import sys
from dotenv import load_dotenv
import queue
import threading
import time
from urllib.parse import quote, urljoin
from typing import Tuple, Dict, Any, List, Optional, Callable
from collections.abc import Callable as CallableABC
import asyncio

# --- –ò–ú–ü–û–†–¢–´ TELEGRAM ---
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup, Message
from telegram.ext import (
    Application,
    CommandHandler,
    MessageHandler,
    CallbackQueryHandler,
    ConversationHandler,
    ContextTypes,
    filters,
)
from telegram.constants import ParseMode


# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –ò –ö–û–ù–°–¢–ê–ù–¢–´ ---
load_dotenv()
BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN", "").strip().strip("'\"")
DB_NAME = "data/hebrew_helper_cache.db"

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–∞—Ä—Å–µ—Ä–∞ –∏ –ë–î
PARSING_TIMEOUT = 15
DB_READ_ATTEMPTS = 5
DB_READ_DELAY = 0.2
CONVERSATION_TIMEOUT_SECONDS = 1800 # 30 –º–∏–Ω—É—Ç
VERB_TRAINER_RETRY_ATTEMPTS = 3

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(format="%(asctime)s - %(name)s - %(levelname)s - %(message)s", level=logging.INFO)
logger = logging.getLogger(__name__)

# --- –ü–û–¢–û–ö–û–ë–ï–ó–û–ü–ê–°–ù–û–°–¢–¨ –ò –ë–õ–û–ö–ò–†–û–í–ö–ò ---
DB_WRITE_QUEUE = queue.Queue()
PARSING_EVENTS = {}
PARSING_EVENTS_LOCK = threading.Lock()

# --- –£–ü–†–ê–í–õ–ï–ù–ò–ï –ë–ê–ó–û–ô –î–ê–ù–ù–´–• (–° –ü–û–î–î–ï–†–ñ–ö–û–ô –¢–†–ê–ù–ó–ê–ö–¶–ò–ô) ---

def db_worker():
    """
    Worker, –∫–æ—Ç–æ—Ä—ã–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ –≤—ã–ø–æ–ª–Ω—è–µ—Ç –∑–∞–ø—Ä–æ—Å—ã –Ω–∞ –∑–∞–ø–∏—Å—å –≤ –ë–î.
    """
    os.makedirs(os.path.dirname(DB_NAME), exist_ok=True)
    conn = sqlite3.connect(DB_NAME, timeout=10)
    conn.execute("PRAGMA journal_mode=WAL;")
    while True:
        try:
            item = DB_WRITE_QUEUE.get()
            if item is None: break
            
            cursor = conn.cursor()
            
            if isinstance(item, CallableABC):
                try:
                    cursor.execute("BEGIN TRANSACTION")
                    item(cursor)
                    conn.commit()
                except Exception as e:
                    logger.error(f"DB-WORKER: –û—à–∏–±–∫–∞ –≤ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–æ–Ω–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏, –æ—Ç–∫–∞—Ç—ã–≤–∞–µ–º. –û—à–∏–±–∫–∞: {e}", exc_info=True)
                    conn.rollback()
            else:
                query, params, is_many = item
                if is_many: cursor.executemany(query, params)
                else: cursor.execute(query, params)
                conn.commit()

        except Exception as e:
            logger.error(f"DB-WORKER: –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}", exc_info=True)

def db_write_query(query, params=(), many=False):
    """–ü–æ–º–µ—â–∞–µ—Ç –æ–¥–∏–Ω–æ—á–Ω—ã–π –∑–∞–ø—Ä–æ—Å –Ω–∞ –∑–∞–ø–∏—Å—å –≤ –æ—á–µ—Ä–µ–¥—å."""
    DB_WRITE_QUEUE.put((query, params, many))

def db_transaction(func: Callable[[sqlite3.Cursor], None]):
    """–ü–æ–º–µ—â–∞–µ—Ç —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –≤–Ω—É—Ç—Ä–∏ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏."""
    DB_WRITE_QUEUE.put(func)

def db_read_query(query, params=(), fetchone=False, fetchall=False):
    """–í—ã–ø–æ–ª–Ω—è–µ—Ç –∑–∞–ø—Ä–æ—Å –Ω–∞ —á—Ç–µ–Ω–∏–µ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç."""
    try:
        conn = sqlite3.connect(DB_NAME, timeout=10, check_same_thread=False)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        cursor.execute(query, params)
        result = None
        if fetchone: result = cursor.fetchone()
        if fetchall: result = cursor.fetchall()
        conn.close()
        return result
    except Exception as e:
        logger.error(f"DB-READ: –û—à–∏–±–∫–∞: {e}")
        return None

def init_db():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ë–î."""
    db_write_query("CREATE TABLE IF NOT EXISTS users (user_id INTEGER PRIMARY KEY, first_name TEXT, username TEXT)")
    db_write_query("CREATE TABLE IF NOT EXISTS cached_words (word_id INTEGER PRIMARY KEY AUTOINCREMENT, hebrew TEXT NOT NULL UNIQUE, translation TEXT NOT NULL, transcription TEXT, is_verb BOOLEAN, root TEXT, binyan TEXT, fetched_at TIMESTAMP)")
    db_write_query("""
        CREATE TABLE IF NOT EXISTS user_dictionary (
            id INTEGER PRIMARY KEY AUTOINCREMENT, 
            user_id INTEGER, 
            word_id INTEGER, 
            added_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP, 
            srs_level INTEGER DEFAULT 0, 
            next_review_at TIMESTAMP, 
            FOREIGN KEY (user_id) REFERENCES users (user_id), 
            FOREIGN KEY (word_id) REFERENCES cached_words (word_id),
            UNIQUE(user_id, word_id) 
        )
    """)
    db_write_query("CREATE TABLE IF NOT EXISTS verb_conjugations (id INTEGER PRIMARY KEY AUTOINCREMENT, word_id INTEGER, tense TEXT, person TEXT, hebrew_form TEXT NOT NULL, transcription TEXT, FOREIGN KEY (word_id) REFERENCES cached_words (word_id))")
    db_write_query("CREATE INDEX IF NOT EXISTS idx_hebrew_form ON verb_conjugations(hebrew_form)")


# --- –ú–û–î–£–õ–¨–ù–ê–Ø –ê–†–•–ò–¢–ï–ö–¢–£–†–ê –ü–ê–†–°–ï–†–ê ---

def local_search(search_word: str) -> Optional[Dict[str, Any]]:
    """–ò—â–µ—Ç —Å–ª–æ–≤–æ –≤ –ª–æ–∫–∞–ª—å–Ω–æ–π –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö."""
    conjugation = db_read_query("SELECT word_id FROM verb_conjugations WHERE hebrew_form = ?", (search_word,), fetchone=True)
    if conjugation:
        word_data = db_read_query("SELECT * FROM cached_words WHERE word_id = ?", (conjugation['word_id'],), fetchone=True)
        if word_data:
            return dict(word_data)

    word_data = db_read_query("SELECT * FROM cached_words WHERE hebrew = ?", (search_word,), fetchone=True)
    if word_data:
        return dict(word_data)

    return None

def parse_verb_page(soup: BeautifulSoup, main_header: Tag) -> Optional[Dict[str, Any]]:
    """–ü–∞—Ä—Å–µ—Ä –¥–ª—è —Å—Ç—Ä–∞–Ω–∏—Ü –≥–ª–∞–≥–æ–ª–æ–≤."""
    logger.info("-> –ó–∞–ø—É—â–µ–Ω parse_verb_page.")
    try:
        data = {'is_verb': True}
        
        logger.info("--> parse_verb_page: –ü–æ–∏—Å–∫ –∏–Ω—Ñ–∏–Ω–∏—Ç–∏–≤–∞...")
        infinitive_div = soup.find('div', id='INF-L')
        if not infinitive_div:
            logger.error("--> parse_verb_page: –ù–µ –Ω–∞–π–¥–µ–Ω –±–ª–æ–∫ –∏–Ω—Ñ–∏–Ω–∏—Ç–∏–≤–∞ INF-L.")
            return None
        
        menukad_tag = infinitive_div.find('span', class_='menukad')
        if not menukad_tag:
            logger.error("--> parse_verb_page: –ù–µ –Ω–∞–π–¥–µ–Ω —Ç–µ–≥ menukad –≤–Ω—É—Ç—Ä–∏ –±–ª–æ–∫–∞ –∏–Ω—Ñ–∏–Ω–∏—Ç–∏–≤–∞.")
            return None
        
        data['hebrew'] = menukad_tag.text.split('~')[0].strip()
        logger.info(f"--> parse_verb_page: –ò–Ω—Ñ–∏–Ω–∏—Ç–∏–≤ –Ω–∞–π–¥–µ–Ω: {data['hebrew']}")
        
        logger.info("--> parse_verb_page: –ü–æ–∏—Å–∫ –ø–µ—Ä–µ–≤–æ–¥–∞ –∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏...")
        data['translation'] = soup.find('div', class_='lead').text.strip()
        data['transcription'] = infinitive_div.find('div', class_='transcription').text.strip()
        
        logger.info("--> parse_verb_page: –ü–æ–∏—Å–∫ –∫–æ—Ä–Ω—è –∏ –±–∏–Ω—å—è–Ω–∞...")
        data['root'], data['binyan'] = None, None
        for p in main_header.find_next_siblings('p'):
            if '–≥–ª–∞–≥–æ–ª' in p.text.lower():
                binyan_tag = p.find('b')
                if binyan_tag: data['binyan'] = binyan_tag.text.strip()
            if '–∫–æ—Ä–µ–Ω—å' in p.text.lower():
                root_tag = p.find('span', class_='menukad')
                if root_tag: data['root'] = root_tag.text.strip()

        logger.info("--> parse_verb_page: –ü–æ–∏—Å–∫ —Å–ø—Ä—è–∂–µ–Ω–∏–π...")
        conjugations = []
        verb_forms = soup.find_all('div', id=re.compile(r'^(AP|PERF|IMPF|IMP|INF)-'))
        tense_map = {'AP': '–Ω–∞—Å—Ç–æ—è—â–µ–µ', 'PERF': '–ø—Ä–æ—à–µ–¥—à–µ–µ', 'IMPF': '–±—É–¥—É—â–µ–µ', 'IMP': '–ø–æ–≤–µ–ª–∏—Ç–µ–ª—å–Ω–æ–µ', 'INF': '–∏–Ω—Ñ–∏–Ω–∏—Ç–∏–≤'}
        for form in verb_forms:
            form_id, menukad_tag, trans_tag = form.get('id'), form.find('span', class_='menukad'), form.find('div', class_='transcription')
            if all([form_id, menukad_tag, trans_tag]):
                tense_prefix = form_id.split('-')[0]
                person = form_id.split('-')[1] if len(form_id.split('-')) > 1 else "—Ñ–æ—Ä–º–∞"
                conjugations.append({'tense': tense_map.get(tense_prefix), 'person': person, 'hebrew_form': menukad_tag.text.strip(), 'transcription': trans_tag.text.strip()})
        data['conjugations'] = conjugations
        logger.info(f"--> parse_verb_page: –ù–∞–π–¥–µ–Ω–æ {len(conjugations)} —Ñ–æ—Ä–º —Å–ø—Ä—è–∂–µ–Ω–∏–π.")
        
        logger.info("-> parse_verb_page –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ.")
        return data
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ parse_verb_page: {e}", exc_info=True)
        return None

def parse_noun_or_adjective_page(soup: BeautifulSoup, main_header: Tag) -> Optional[Dict[str, Any]]:
    """–ü–∞—Ä—Å–µ—Ä –¥–ª—è —Å—Ç—Ä–∞–Ω–∏—Ü —Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã—Ö –∏ –ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω—ã—Ö."""
    logger.info("-> –ó–∞–ø—É—â–µ–Ω parse_noun_or_adjective_page.")
    try:
        data = {'is_verb': False, 'root': None, 'binyan': None, 'conjugations': []}
        
        logger.info("--> parse_noun_or_adjective_page: –ü–æ–∏—Å–∫ –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–æ–π —Ñ–æ—Ä–º—ã...")
        canonical_hebrew = None
        canonical_tag = main_header.find('span', class_='menukad')
        if canonical_tag:
            canonical_hebrew = canonical_tag.text.strip()
        elif soup.title and '‚Äì' in soup.title.string:
            potential_word = soup.title.string.split('‚Äì')[0].strip()
            if re.match(r'^[\u0590-\u05FF\s-]+$', potential_word):
                canonical_hebrew = potential_word
        
        if not canonical_hebrew: 
            logger.error("--> parse_noun_or_adjective_page: –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫—É—é —Ñ–æ—Ä–º—É.")
            return None
        data['hebrew'] = canonical_hebrew
        logger.info(f"--> parse_noun_or_adjective_page: –ö–∞–Ω–æ–Ω–∏—á–µ—Å–∫–∞—è —Ñ–æ—Ä–º–∞ –Ω–∞–π–¥–µ–Ω–∞: {data['hebrew']}")
        
        logger.info("--> parse_noun_or_adjective_page: –ü–æ–∏—Å–∫ –ø–µ—Ä–µ–≤–æ–¥–∞ –∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏...")
        data['translation'] = soup.find('div', class_='lead').text.strip()
        data['transcription'] = soup.find('div', class_='transcription').text.strip()
        
        logger.info("-> parse_noun_or_adjective_page –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ.")
        return data
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ parse_noun_or_adjective_page: {e}", exc_info=True)
        return None

def fetch_and_cache_word_data(search_word: str) -> Tuple[str, Optional[Dict[str, Any]]]:
    """–§—É–Ω–∫—Ü–∏—è-–¥–∏—Å–ø–µ—Ç—á–µ—Ä –ø–∞—Ä—Å–∏–Ω–≥–∞."""
    is_owner = False
    with PARSING_EVENTS_LOCK:
        if search_word not in PARSING_EVENTS:
            PARSING_EVENTS[search_word] = threading.Event()
            is_owner = True
        event = PARSING_EVENTS[search_word]

    if not is_owner:
        logger.info(f"–ü–∞—Ä—Å–∏–Ω–≥ —Å–ª–æ–≤–∞ '{search_word}' —É–∂–µ –∑–∞–ø—É—â–µ–Ω –¥—Ä—É–≥–∏–º –ø–æ—Ç–æ–∫–æ–º, –æ–∂–∏–¥–∞–Ω–∏–µ...")
        event.wait(timeout=PARSING_TIMEOUT)
        logger.info(f"–û–∂–∏–¥–∞–Ω–∏–µ –¥–ª—è '{search_word}' –∑–∞–≤–µ—Ä—à–µ–Ω–æ, –ø–æ–≤—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ –≤ –∫—ç—à–µ.")
        result = local_search(search_word)
        return ('ok', result) if result else ('not_found', None)

    try:
        logger.info(f"--- –ù–∞—á–∞–ª–æ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–ª—è '{search_word}' ---")
        
        logger.info("–®–∞–≥ 1: –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ HTTP-–∑–∞–ø—Ä–æ—Å–∞...")
        try:
            search_url = f"https://www.pealim.com/ru/search/?q={quote(search_word)}"
            session = requests.Session()
            headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36'}
            session.headers.update(headers)
            search_response = session.get(search_url, timeout=10)
            search_response.raise_for_status()
            logger.info(f"–®–∞–≥ 1.1: –£—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ç {search_url}")
            
            if "/dict/" in search_response.url:
                response = search_response
                logger.info("–®–∞–≥ 1.2: –ü—Ä—è–º–æ–µ –ø–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –Ω–∞ —Å–ª–æ–≤–∞—Ä–Ω—É—é —Å—Ç–∞—Ç—å—é.")
            else:
                logger.info("–®–∞–≥ 1.2: –û—Ç–≤–µ—Ç - —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –ø–æ–∏—Å–∫–∞, –∏—â–µ–º –Ω—É–∂–Ω—É—é —Å—Å—ã–ª–∫—É...")
                search_soup = BeautifulSoup(search_response.text, 'html.parser')
                results_container = search_soup.find('div', class_='results-by-verb') or search_soup.find('div', class_='results-by-meaning')
                if not results_container: return 'not_found', None
                result_link = results_container.find('a', href=re.compile(r'/dict/'))
                if not result_link or not result_link.get('href'): return 'not_found', None
                final_url = urljoin(search_response.url, result_link['href'])
                logger.info(f"–®–∞–≥ 1.3: –ù–∞–π–¥–µ–Ω–∞ —Å—Å—ã–ª–∫–∞, –ø–µ—Ä–µ—Ö–æ–¥ –Ω–∞ {final_url}")
                response = session.get(final_url, timeout=10)
                response.raise_for_status()
        except requests.RequestException as e:
            logger.error(f"–°–µ—Ç–µ–≤–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ pealim.com: {e}")
            return 'error', None
        
        logger.info("–®–∞–≥ 1.4: –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞.")
        soup = BeautifulSoup(response.text, 'html.parser')
        
        logger.info("–®–∞–≥ 2: –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã...")
        main_header = soup.find('h2', class_='page-header')
        if not main_header: return 'error', None

        parsed_data = None
        if "—Å–ø—Ä—è–∂–µ–Ω–∏–µ" in main_header.text.lower():
            logger.info("–®–∞–≥ 2.1: –°—Ç—Ä–∞–Ω–∏—Ü–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –∫–∞–∫ –ì–õ–ê–ì–û–õ.")
            parsed_data = parse_verb_page(soup, main_header)
        else:
            logger.info("–®–∞–≥ 2.1: –°—Ç—Ä–∞–Ω–∏—Ü–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –∫–∞–∫ –°–£–©–ï–°–¢–í–ò–¢–ï–õ–¨–ù–û–ï/–ü–†–ò–õ–ê–ì–ê–¢–ï–õ–¨–ù–û–ï.")
            parsed_data = parse_noun_or_adjective_page(soup, main_header)

        logger.info("–®–∞–≥ 3: –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞...")
        if not parsed_data: return 'error', None
        logger.info(f"–®–∞–≥ 3.1: –ü–∞—Ä—Å–µ—Ä —É—Å–ø–µ—à–Ω–æ –≤–µ—Ä–Ω—É–ª –¥–∞–Ω–Ω—ã–µ –¥–ª—è '{parsed_data['hebrew']}'.")
        
        if local_search(parsed_data['hebrew']):
            logger.info(f"–®–∞–≥ 3.2: –ö–∞–Ω–æ–Ω–∏—á–µ—Å–∫–∞—è —Ñ–æ—Ä–º–∞ '{parsed_data['hebrew']}' —É–∂–µ –µ—Å—Ç—å –≤ –∫—ç—à–µ. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è.")
            return 'ok', local_search(parsed_data['hebrew'])

        logger.info(f"–®–∞–≥ 4: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ '{parsed_data['hebrew']}' –≤ –ë–î...")
        def _save_word_transaction(cursor: sqlite3.Cursor):
            cursor.execute("INSERT OR IGNORE INTO cached_words (hebrew, translation, transcription, is_verb, root, binyan, fetched_at) VALUES (?, ?, ?, ?, ?, ?, ?)",
                           (parsed_data['hebrew'], parsed_data['translation'], parsed_data['transcription'], parsed_data['is_verb'], parsed_data['root'], parsed_data['binyan'], datetime.now()))
            word_id = cursor.lastrowid
            if word_id and parsed_data.get('conjugations'):
                conjugations_to_insert = [(word_id, c['tense'], c['person'], c['hebrew_form'], c['transcription']) for c in parsed_data['conjugations']]
                cursor.executemany("INSERT INTO verb_conjugations (word_id, tense, person, hebrew_form, transcription) VALUES (?, ?, ?, ?, ?)", conjugations_to_insert)
        db_transaction(_save_word_transaction)
        logger.info("–®–∞–≥ 4.1: –¢—Ä–∞–Ω–∑–∞–∫—Ü–∏—è –Ω–∞ –∑–∞–ø–∏—Å—å –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∞ –≤ –æ—á–µ—Ä–µ–¥—å.")
        
        logger.info("–®–∞–≥ 5: –û–∂–∏–¥–∞–Ω–∏–µ –ø–æ—è–≤–ª–µ–Ω–∏—è —Å–ª–æ–≤–∞ –≤ –ë–î –∏ –≤–æ–∑–≤—Ä–∞—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞...")
        final_word_data = None
        for i in range(DB_READ_ATTEMPTS):
            logger.info(f"–®–∞–≥ 5.{i+1}: –ü–æ–ø—ã—Ç–∫–∞ —á—Ç–µ–Ω–∏—è –∏–∑ –ë–î...")
            final_word_data = local_search(parsed_data['hebrew'])
            if final_word_data:
                logger.info("–®–∞–≥ 5.x: –°–ª–æ–≤–æ —É—Å–ø–µ—à–Ω–æ –Ω–∞–π–¥–µ–Ω–æ –≤ –ë–î.")
                break
            time.sleep(DB_READ_DELAY)
        
        if final_word_data:
            logger.info(f"--- –ü–∞—Ä—Å–∏–Ω–≥ –¥–ª—è '{search_word}' –∑–∞–≤–µ—Ä—à–µ–Ω –£–°–ü–ï–®–ù–û. ---")
            return ('ok', final_word_data)
        else:
            logger.error(f"--- –ü–∞—Ä—Å–∏–Ω–≥ –¥–ª—è '{search_word}' –∑–∞–≤–µ—Ä—à–µ–Ω —Å –û–®–ò–ë–ö–û–ô –ë–î (–Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å –∑–∞–ø–∏—Å—å). ---")
            return ('db_error', None)
            
    except Exception as e:
        logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ fetch_and_cache_word_data: {e}", exc_info=True)
        return 'error', None
    finally:
        logger.info(f"–®–∞–≥ 6: –û—á–∏—Å—Ç–∫–∞ –¥–ª—è '{search_word}'.")
        with PARSING_EVENTS_LOCK:
            if search_word in PARSING_EVENTS:
                PARSING_EVENTS[search_word].set()
                del PARSING_EVENTS[search_word]

# --- –ö–û–õ–õ–ë–≠–ö-–î–ê–ù–ù–´–ï –ò –°–û–°–¢–û–Ø–ù–ò–Ø ---
TRAINING_MENU_STATE, FLASHCARD_SHOW, FLASHCARD_EVAL, AWAITING_VERB_ANSWER = range(4)
CB_DICT_VIEW, CB_DICT_DELETE_MODE, CB_DICT_CONFIRM_DELETE, CB_DICT_EXECUTE_DELETE = "d_v", "d_dm", "d_cd", "d_ed"
CB_ADD, CB_SHOW_VERB, CB_VIEW_CARD = "add", "sh_v", "v_c"
CB_TRAIN_MENU, CB_TRAIN_HE_RU, CB_TRAIN_RU_HE, CB_VERB_TRAINER_START = "t_m", "t_hr", "t_rh", "vts"
CB_SHOW_ANSWER, CB_EVAL_CORRECT, CB_EVAL_INCORRECT, CB_END_TRAINING = "sh_a", "e_c", "e_i", "e_t"

# --- –û–°–ù–û–í–ù–´–ï –•–ï–ù–î–õ–ï–†–´ ---

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user = update.effective_user
    db_write_query("INSERT OR IGNORE INTO users (user_id, first_name, username) VALUES (?, ?, ?)", (user.id, user.first_name, user.username))
    keyboard = [[InlineKeyboardButton("üß† –ú–æ–π —Å–ª–æ–≤–∞—Ä—å", callback_data=f"{CB_DICT_VIEW}_0")], [InlineKeyboardButton("üí™ –¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞", callback_data=CB_TRAIN_MENU)]]
    await update.message.reply_text(f"–ü—Ä–∏–≤–µ—Ç, {user.first_name}! –û—Ç–ø—Ä–∞–≤—å –º–Ω–µ —Å–ª–æ–≤–æ –Ω–∞ –∏–≤—Ä–∏—Ç–µ –¥–ª—è –ø–æ–∏—Å–∫–∞.", reply_markup=InlineKeyboardMarkup(keyboard))

async def main_menu(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    keyboard = [[InlineKeyboardButton("üß† –ú–æ–π —Å–ª–æ–≤–∞—Ä—å", callback_data=f"{CB_DICT_VIEW}_0")], [InlineKeyboardButton("üí™ –¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞", callback_data=CB_TRAIN_MENU)]]
    await query.edit_message_text("–ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é:", reply_markup=InlineKeyboardMarkup(keyboard))

async def display_word_card(
    context: ContextTypes.DEFAULT_TYPE,
    user_id: int,
    chat_id: int,
    word_data: dict,
    message_id: Optional[int] = None,
    in_dictionary: Optional[bool] = None
):
    """
    –û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç –∫–∞—Ä—Ç–æ—á–∫—É —Å–ª–æ–≤–∞. –†–µ–¥–∞–∫—Ç–∏—Ä—É–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ, –µ—Å–ª–∏
    –ø–µ—Ä–µ–¥–∞–Ω message_id, –∏–Ω–∞—á–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –Ω–æ–≤–æ–µ.
    """
    word_id = word_data['word_id']
    
    if in_dictionary is None:
        in_dictionary = db_read_query("SELECT 1 FROM user_dictionary WHERE user_id = ? AND word_id = ?", (user_id, word_id), fetchone=True)
    
    card_text = f"–ù–∞–π–¥–µ–Ω–æ: *{word_data['hebrew']}* [{word_data.get('transcription', '')}]\n–ü–µ—Ä–µ–≤–æ–¥: {word_data['translation']}"
    keyboard_buttons = []
    
    if in_dictionary:
        card_text = f"–°–ª–æ–≤–æ *{word_data['hebrew']}* —É–∂–µ –≤ –≤–∞—à–µ–º —Å–ª–æ–≤–∞—Ä–µ.\n–ü–µ—Ä–µ–≤–æ–¥: {word_data['translation']}"
        keyboard_buttons.append(InlineKeyboardButton("üóëÔ∏è –£–¥–∞–ª–∏—Ç—å", callback_data=f"{CB_DICT_CONFIRM_DELETE}_{word_id}_0"))
    else:
        keyboard_buttons.append(InlineKeyboardButton("‚ûï –î–æ–±–∞–≤–∏—Ç—å", callback_data=f"{CB_ADD}_{word_id}"))

    if word_data.get('is_verb'):
        keyboard_buttons.append(InlineKeyboardButton("üìñ –°–ø—Ä—è–∂–µ–Ω–∏—è", callback_data=f"{CB_SHOW_VERB}_{word_id}"))

    keyboard = [keyboard_buttons, [InlineKeyboardButton("‚¨ÖÔ∏è –í –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é", callback_data="main_menu")]]
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    try:
        if message_id:
            await context.bot.edit_message_text(chat_id=chat_id, message_id=message_id, text=card_text, reply_markup=reply_markup, parse_mode=ParseMode.MARKDOWN)
        else:
            await context.bot.send_message(chat_id=chat_id, text=card_text, reply_markup=reply_markup, parse_mode=ParseMode.MARKDOWN)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ/—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ –∫–∞—Ä—Ç–æ—á–∫–∏ —Å–ª–æ–≤–∞: {e}", exc_info=True)

async def handle_text_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not update.message or not update.message.text: return
    text = update.message.text.strip()
    user_id = update.effective_user.id
    chat_id = update.effective_chat.id
    
    if not re.match(r'^[\u0590-\u05FF\s-]+$', text):
        await update.message.reply_text("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ç–æ–ª—å–∫–æ –±—É–∫–≤—ã –∏–≤—Ä–∏—Ç–∞, –ø—Ä–æ–±–µ–ª—ã –∏ –¥–µ—Ñ–∏—Å—ã.")
        return
    if len(text.split()) > 1:
        await update.message.reply_text("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤–ª—è–π—Ç–µ —Ç–æ–ª—å–∫–æ –ø–æ –æ–¥–Ω–æ–º—É —Å–ª–æ–≤—É –∑–∞ —Ä–∞–∑.")
        return

    word_data = local_search(text)
    if word_data:
        await display_word_card(context, user_id, chat_id, word_data)
        return

    status_message = await update.message.reply_text("üîé –ò—â—É —Å–ª–æ–≤–æ –≤–æ –≤–Ω–µ—à–Ω–µ–º —Å–ª–æ–≤–∞—Ä–µ...")
    
    status, data = await asyncio.to_thread(fetch_and_cache_word_data, text)

    if status == 'ok' and data:
        await display_word_card(context, user_id, chat_id, data, message_id=status_message.message_id)
    elif status == 'not_found':
        await context.bot.edit_message_text(f"–°–ª–æ–≤–æ '{text}' –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.", chat_id=chat_id, message_id=status_message.message_id)
    elif status == 'error':
        await context.bot.edit_message_text("–í–Ω–µ—à–Ω–∏–π —Å–µ—Ä–≤–∏—Å —Å–ª–æ–≤–∞—Ä—è –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–∑–∂–µ.", chat_id=chat_id, message_id=status_message.message_id)
    elif status == 'db_error':
        await context.bot.edit_message_text("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –≤–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —Å–ª–æ–≤–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.", chat_id=chat_id, message_id=status_message.message_id)

async def add_word_to_dictionary(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    word_id = int(query.data.split('_')[1])
    user_id = query.from_user.id
    chat_id = query.message.chat_id
    message_id = query.message.message_id

    db_write_query("INSERT OR IGNORE INTO user_dictionary (user_id, word_id, next_review_at) VALUES (?, ?, ?)", (user_id, word_id, datetime.now()))
    
    await query.answer("–î–æ–±–∞–≤–ª–µ–Ω–æ!")

    word_data = db_read_query("SELECT * FROM cached_words WHERE word_id = ?", (word_id,), fetchone=True)
    if word_data:
        await display_word_card(context, user_id, chat_id, dict(word_data), message_id=message_id, in_dictionary=True)

async def view_dictionary_page_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    parts = query.data.split('_')
    page = int(parts[-1])
    deletion_mode = parts[1] == "dm"
    await view_dictionary_page_logic(update, context, page=page, deletion_mode=deletion_mode)

async def view_dictionary_page_logic(update: Update, context: ContextTypes.DEFAULT_TYPE, page: int, deletion_mode: bool, exclude_word_id: Optional[int] = None):
    query = update.callback_query
    user_id = query.from_user.id
    
    words_from_db = db_read_query("SELECT cw.word_id, cw.hebrew, cw.translation FROM cached_words cw JOIN user_dictionary ud ON cw.word_id = ud.word_id WHERE ud.user_id = ? ORDER BY ud.added_at DESC LIMIT 6 OFFSET ?", (user_id, page * 5), fetchall=True)
    
    words = [w for w in words_from_db if w['word_id'] != exclude_word_id] if exclude_word_id else words_from_db
    
    has_next_page = len(words) > 5
    words = words[:5]

    if not words and page > 0:
        return await view_dictionary_page_logic(update, context, page=page - 1, deletion_mode=False)
    if not words and page == 0:
        await query.edit_message_text("–í–∞—à —Å–ª–æ–≤–∞—Ä—å –ø—É—Å—Ç.", reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton("‚¨ÖÔ∏è –í –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é", callback_data="main_menu")]]))
        return

    keyboard, message_text = [], "–í–∞—à —Å–ª–æ–≤–∞—Ä—å (—Å—Ç—Ä. {}):\n\n".format(page + 1)
    if deletion_mode: message_text = "–í—ã–±–µ—Ä–∏—Ç–µ —Å–ª–æ–≤–æ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è:"
    for word in words:
        if deletion_mode:
            keyboard.append([InlineKeyboardButton(f"üóëÔ∏è {word['hebrew']}", callback_data=f"{CB_DICT_CONFIRM_DELETE}_{word['word_id']}_{page}")])
        else:
            message_text += f"‚Ä¢ {word['hebrew']} ‚Äî {word['translation']}\n"
    
    nav_buttons = []
    nav_pattern = CB_DICT_DELETE_MODE if deletion_mode else CB_DICT_VIEW
    if page > 0: nav_buttons.append(InlineKeyboardButton("‚óÄÔ∏è", callback_data=f"{nav_pattern}_{page-1}"))
    if has_next_page: nav_buttons.append(InlineKeyboardButton("‚ñ∂Ô∏è", callback_data=f"{nav_pattern}_{page+1}"))
    if nav_buttons: keyboard.append(nav_buttons)
    
    if deletion_mode:
        keyboard.append([InlineKeyboardButton("‚¨ÖÔ∏è –ö —Å–ª–æ–≤–∞—Ä—é", callback_data=f"{CB_DICT_VIEW}_{page}")])
    else:
        keyboard.append([InlineKeyboardButton("üóëÔ∏è –£–¥–∞–ª–∏—Ç—å —Å–ª–æ–≤–æ", callback_data=f"{CB_DICT_DELETE_MODE}_0")])
        keyboard.append([InlineKeyboardButton("‚¨ÖÔ∏è –í –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é", callback_data="main_menu")])
    
    await query.edit_message_text(message_text, reply_markup=InlineKeyboardMarkup(keyboard))

async def confirm_delete_word(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    _, _, word_id_str, page_str = query.data.split('_')
    word_data = db_read_query("SELECT hebrew FROM cached_words WHERE word_id = ?", (word_id_str,), fetchone=True)
    if not word_data:
        await query.edit_message_text("–û—à–∏–±–∫–∞: —Å–ª–æ–≤–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
        return
    text = f"–£–¥–∞–ª–∏—Ç—å —Å–ª–æ–≤–æ '{word_data['hebrew']}'?"
    keyboard = [[InlineKeyboardButton("‚úÖ –î–∞", callback_data=f"{CB_DICT_EXECUTE_DELETE}_{word_id_str}_{page_str}")], [InlineKeyboardButton("‚ùå –ù–µ—Ç", callback_data=f"{CB_DICT_DELETE_MODE}_{page_str}")]]
    await query.edit_message_text(text, reply_markup=InlineKeyboardMarkup(keyboard))

async def execute_delete_word(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer("–°–ª–æ–≤–æ —É–¥–∞–ª–µ–Ω–æ")
    _, _, word_id_str, page_str = query.data.split('_')
    word_id, page = int(word_id_str), int(page_str)
    
    db_write_query("DELETE FROM user_dictionary WHERE user_id = ? AND word_id = ?", (query.from_user.id, word_id))
    
    await view_dictionary_page_logic(update, context, page=page, deletion_mode=False, exclude_word_id=word_id)

async def training_menu(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    if query: await query.answer()
    keyboard = [[InlineKeyboardButton("üáÆüá± ‚Üí üá∑üá∫", callback_data=CB_TRAIN_HE_RU)], [InlineKeyboardButton("üá∑üá∫ ‚Üí üáÆüá±", callback_data=CB_TRAIN_RU_HE)], [InlineKeyboardButton("üî• –ì–ª–∞–≥–æ–ª—ã", callback_data=CB_VERB_TRAINER_START)], [InlineKeyboardButton("‚¨ÖÔ∏è –í –º–µ–Ω—é", callback_data="main_menu")]]
    await (query.edit_message_text if query else update.message.reply_text)("–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏:", reply_markup=InlineKeyboardMarkup(keyboard))
    return TRAINING_MENU_STATE

async def start_flashcard_training(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    context.user_data['training_mode'] = query.data
    words = db_read_query("SELECT cw.* FROM cached_words cw JOIN user_dictionary ud ON cw.word_id = ud.word_id WHERE ud.user_id = ? AND cw.is_verb = 0 ORDER BY ud.next_review_at ASC LIMIT 10", (query.from_user.id,), fetchall=True)
    if not words:
        await query.edit_message_text("–í —Å–ª–æ–≤–∞—Ä–µ –Ω–µ—Ç —Å–ª–æ–≤ –¥–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏.", reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton("‚¨ÖÔ∏è –ù–∞–∑–∞–¥", callback_data=CB_TRAIN_MENU)]]))
        return ConversationHandler.END
    context.user_data.update({'words': [dict(w) for w in words], 'idx': 0, 'correct': 0})
    return await show_next_card(update, context)

async def show_next_card(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    if query: await query.answer()
    idx, words = context.user_data['idx'], context.user_data['words']
    if idx >= len(words):
        await query.edit_message_text(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {context.user_data['correct']}/{len(words)}", reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton("üí™ –ï—â–µ", callback_data=context.user_data['training_mode'])], [InlineKeyboardButton("‚¨ÖÔ∏è –í –º–µ–Ω—é", callback_data=CB_TRAIN_MENU)]]))
        return ConversationHandler.END
    word = words[idx]
    question = word['hebrew'] if context.user_data['training_mode'] == CB_TRAIN_HE_RU else word['translation']
    keyboard = [[InlineKeyboardButton("üí° –û—Ç–≤–µ—Ç", callback_data=CB_SHOW_ANSWER)], [InlineKeyboardButton("‚ùå –ó–∞–∫–æ–Ω—á–∏—Ç—å", callback_data=CB_END_TRAINING)]]
    
    message_text = f"–°–ª–æ–≤–æ {idx+1}/{len(words)}:\n\n*{question}*"
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    if query:
        await query.edit_message_text(text=message_text, reply_markup=reply_markup, parse_mode=ParseMode.MARKDOWN)
    else: # Should not happen in this flow, but as a fallback
        await context.bot.send_message(chat_id=update.effective_chat.id, text=message_text, reply_markup=reply_markup, parse_mode=ParseMode.MARKDOWN)

    return FLASHCARD_SHOW

async def show_answer(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    word = context.user_data['words'][context.user_data['idx']]
    answer_text = f"*{word['hebrew']}* [{word['transcription']}]\n–ü–µ—Ä–µ–≤–æ–¥: {word['translation']}"
    keyboard = [[InlineKeyboardButton("‚úÖ –ó–Ω–∞—é", callback_data=CB_EVAL_CORRECT)], [InlineKeyboardButton("‚ùå –ù–µ –∑–Ω–∞—é", callback_data=CB_EVAL_INCORRECT)]]
    await query.edit_message_text(answer_text, reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN)
    return FLASHCARD_EVAL

async def handle_self_evaluation(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    word = context.user_data['words'][context.user_data['idx']]
    srs_data = db_read_query("SELECT srs_level FROM user_dictionary WHERE user_id = ? AND word_id = ?", (query.from_user.id, word['word_id']), fetchone=True)
    srs_level = srs_data['srs_level'] if srs_data else 0
    if query.data == CB_EVAL_CORRECT:
        context.user_data['correct'] += 1
        srs_level += 1
    else: srs_level = 0
    next_review_date = datetime.now() + timedelta(days=[0, 1, 3, 7, 14, 30, 90][min(srs_level, 6)])
    db_write_query("UPDATE user_dictionary SET srs_level = ?, next_review_at = ? WHERE user_id = ? AND word_id = ?", (srs_level, next_review_date, query.from_user.id, word['word_id']))
    context.user_data['idx'] += 1
    return await show_next_card(update, context)

async def start_verb_trainer(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    
    user_id = query.from_user.id
    verb, conjugation = None, None

    for i in range(VERB_TRAINER_RETRY_ATTEMPTS):
        verb_candidate = db_read_query("SELECT cw.* FROM cached_words cw JOIN user_dictionary ud ON cw.word_id = ud.word_id WHERE ud.user_id = ? AND cw.is_verb = 1 ORDER BY RANDOM() LIMIT 1", (user_id,), fetchone=True)
        if not verb_candidate:
            await query.edit_message_text("–í –≤–∞—à–µ–º —Å–ª–æ–≤–∞—Ä–µ –Ω–µ—Ç –≥–ª–∞–≥–æ–ª–æ–≤ –¥–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏.", reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton("‚¨ÖÔ∏è –ù–∞–∑–∞–¥", callback_data=CB_TRAIN_MENU)]]))
            return ConversationHandler.END

        conjugation_candidate = db_read_query("SELECT * FROM verb_conjugations WHERE word_id = ? ORDER BY RANDOM() LIMIT 1", (verb_candidate['word_id'],), fetchone=True)
        if conjugation_candidate:
            verb, conjugation = verb_candidate, conjugation_candidate
            break
        else:
            logger.warning(f"–û—à–∏–±–∫–∞ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö: —É –≥–ª–∞–≥–æ–ª–∞ {verb_candidate['hebrew']} (id: {verb_candidate['word_id']}) –Ω–µ—Ç —Å–ø—Ä—è–∂–µ–Ω–∏–π. –ü–æ–ø—ã—Ç–∫–∞ {i+1}/{VERB_TRAINER_RETRY_ATTEMPTS}")

    if not verb or not conjugation:
        await query.edit_message_text("–í–æ–∑–Ω–∏–∫–ª–∞ –ø—Ä–æ–±–ª–µ–º–∞ —Å –¥–∞–Ω–Ω—ã–º–∏ –¥–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏.", reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton("‚¨ÖÔ∏è –ù–∞–∑–∞–¥", callback_data=CB_TRAIN_MENU)]]))
        return ConversationHandler.END

    context.user_data['answer'] = dict(conjugation)
    await query.edit_message_text(f"–ì–ª–∞–≥–æ–ª: *{verb['hebrew']}*\n–ù–∞–ø–∏—à–∏—Ç–µ —Ñ–æ—Ä–º—É –¥–ª—è: *{conjugation['tense']}, {conjugation['person']}*", parse_mode=ParseMode.MARKDOWN)
    return AWAITING_VERB_ANSWER

async def check_verb_answer(update: Update, context: ContextTypes.DEFAULT_TYPE):
    correct = context.user_data['answer']
    if update.message.text.strip() == correct['hebrew_form']:
        await update.message.reply_text(f"‚úÖ –í–µ—Ä–Ω–æ! *{correct['hebrew_form']}*", parse_mode=ParseMode.MARKDOWN)
    else:
        await update.message.reply_text(f"‚ùå –ù–µ–≤–µ—Ä–Ω–æ. –ü—Ä–∞–≤–∏–ª—å–Ω–æ: *{correct['hebrew_form']}*", parse_mode=ParseMode.MARKDOWN)
    db_write_query("UPDATE user_dictionary SET next_review_at = ? WHERE user_id = ? AND word_id = ?", (datetime.now() + timedelta(days=1), update.effective_user.id, correct['word_id']))
    keyboard = [[InlineKeyboardButton("üî• –ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å", callback_data=CB_VERB_TRAINER_START)], [InlineKeyboardButton("‚¨ÖÔ∏è –í –º–µ–Ω—é", callback_data=CB_TRAIN_MENU)]]
    await update.message.reply_text("–ß—Ç–æ –¥–∞–ª—å—à–µ?", reply_markup=InlineKeyboardMarkup(keyboard))
    return ConversationHandler.END

async def end_training(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    await query.edit_message_text("–¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞.")
    await training_menu(update, context)
    return ConversationHandler.END

async def back_to_main_menu(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await main_menu(update, context)
    return ConversationHandler.END

async def show_verb_conjugations(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    word_id = int(query.data.split('_')[-1])
    word_info = db_read_query("SELECT hebrew FROM cached_words WHERE word_id = ?", (word_id,), fetchone=True)
    conjugations_raw = db_read_query("SELECT tense, person, hebrew_form, transcription FROM verb_conjugations WHERE word_id = ? ORDER BY id", (word_id,), fetchall=True)
    
    keyboard = [[InlineKeyboardButton("‚¨ÖÔ∏è –ù–∞–∑–∞–¥ –∫ —Å–ª–æ–≤—É", callback_data=f"{CB_VIEW_CARD}_{word_id}")]]

    if not conjugations_raw or not word_info:
        await query.edit_message_text("–î–ª—è —ç—Ç–æ–≥–æ –≥–ª–∞–≥–æ–ª–∞ –Ω–µ—Ç —Ç–∞–±–ª–∏—Ü—ã —Å–ø—Ä—è–∂–µ–Ω–∏–π.", reply_markup=InlineKeyboardMarkup(keyboard))
        return
        
    conjugations_by_tense = {}
    message_text = f"–°–ø—Ä—è–∂–µ–Ω–∏—è –¥–ª—è *{word_info['hebrew']}*:\n"
    
    for conj in conjugations_raw:
        if conj['tense'] not in conjugations_by_tense: conjugations_by_tense[conj['tense']] = []
        conjugations_by_tense[conj['tense']].append(conj)
        
    for tense, conjugations in conjugations_by_tense.items():
        message_text += f"\n*{tense.capitalize()}*:\n"
        for conj in conjugations: message_text += f"_{conj['person']}_: {conj['hebrew_form']} ({conj['transcription']})\n"
            
    if len(message_text) > 4096: message_text = message_text[:4090] + "\n(...)"
    
    await query.edit_message_text(message_text, reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN)

async def view_word_card_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –∫–∞—Ä—Ç–æ—á–∫–∏ —Å–ª–æ–≤–∞ –ø–æ –µ–≥–æ ID."""
    query = update.callback_query
    await query.answer()
    word_id = int(query.data.split('_')[-1])
    user_id = query.from_user.id
    chat_id = query.message.chat_id
    message_id = query.message.message_id
    
    word_data = db_read_query("SELECT * FROM cached_words WHERE word_id = ?", (word_id,), fetchone=True)
    if word_data:
        await display_word_card(context, user_id, chat_id, dict(word_data), message_id=message_id)
    else:
        await query.edit_message_text("–û—à–∏–±–∫–∞: —Å–ª–æ–≤–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.", reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton("‚¨ÖÔ∏è –í –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é", callback_data="main_menu")]]))


def main() -> None:
    if not BOT_TOKEN:
        logger.critical("–¢–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω. –£–∫–∞–∂–∏—Ç–µ TELEGRAM_BOT_TOKEN –≤ .env —Ñ–∞–π–ª–µ.")
        sys.exit("–¢–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω.")

    db_worker_thread = threading.Thread(target=db_worker, daemon=True)
    db_worker_thread.start()
    init_db()
    
    application = Application.builder().token(BOT_TOKEN).build()

    conv_defaults = {"per_user": True, "per_chat": True, "conversation_timeout": CONVERSATION_TIMEOUT_SECONDS}

    training_conv = ConversationHandler(
        entry_points=[CallbackQueryHandler(training_menu, pattern=f"^{CB_TRAIN_MENU}$")],
        states={
            TRAINING_MENU_STATE: [
                CallbackQueryHandler(start_flashcard_training, pattern=f"^({CB_TRAIN_HE_RU}|{CB_TRAIN_RU_HE})$"),
                CallbackQueryHandler(start_verb_trainer, pattern=f"^{CB_VERB_TRAINER_START}$"),
                CallbackQueryHandler(back_to_main_menu, pattern="^main_menu$")
            ],
            FLASHCARD_SHOW: [
                CallbackQueryHandler(show_answer, pattern=f"^{CB_SHOW_ANSWER}$"),
                CallbackQueryHandler(end_training, pattern=f"^{CB_END_TRAINING}$")
            ],
            FLASHCARD_EVAL: [
                CallbackQueryHandler(handle_self_evaluation, pattern=f"^{CB_EVAL_CORRECT}|{CB_EVAL_INCORRECT}$")
            ],
            AWAITING_VERB_ANSWER: [
                MessageHandler(filters.TEXT & ~filters.COMMAND, check_verb_answer)
            ],
        },
        fallbacks=[
            CallbackQueryHandler(end_training, pattern=f"^{CB_END_TRAINING}$"),
            CallbackQueryHandler(back_to_main_menu, pattern="^main_menu$"),
            CallbackQueryHandler(training_menu, pattern=f"^{CB_TRAIN_MENU}$")
        ],
        map_to_parent={
            ConversationHandler.END: TRAINING_MENU_STATE
        },
        **conv_defaults
    )

    application.add_handler(CommandHandler("start", start))
    application.add_handler(CallbackQueryHandler(main_menu, pattern="^main_menu$"))
    application.add_handler(CallbackQueryHandler(view_dictionary_page_handler, pattern=f"^{CB_DICT_VIEW}_|{CB_DICT_DELETE_MODE}_"))
    application.add_handler(CallbackQueryHandler(confirm_delete_word, pattern=f"^{CB_DICT_CONFIRM_DELETE}_"))
    application.add_handler(CallbackQueryHandler(execute_delete_word, pattern=f"^{CB_DICT_EXECUTE_DELETE}_"))
    application.add_handler(CallbackQueryHandler(add_word_to_dictionary, pattern=f"^{CB_ADD}_"))
    application.add_handler(CallbackQueryHandler(show_verb_conjugations, pattern=f"^{CB_SHOW_VERB}_"))
    application.add_handler(CallbackQueryHandler(view_word_card_handler, pattern=f"^{CB_VIEW_CARD}_"))
    application.add_handler(training_conv)
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text_message))

    logger.info("–ë–æ—Ç –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è...")
    application.run_polling()
    
    DB_WRITE_QUEUE.put(None)
    db_worker_thread.join()

if __name__ == "__main__":
    main()
